{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "coated-vegetation",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Single Machine Distributed Computation in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "smart-maria",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Outcomes\n",
    "\n",
    "### 1. Understand computer science things \n",
    "\n",
    "- concurrency, parallelism & asynchrony.\n",
    "\n",
    "### 2. Understand hardware / software things \n",
    "\n",
    "- CPU cores, threads & processes.\n",
    "\n",
    "### 3. How to distribute compute in Python on a single machine (standard library only)\n",
    "\n",
    "- why to never use `threading`,\n",
    "- why `multiprocessing` - (use for CPU bound tasks),\n",
    "- single thread + `asyncio` - (use for IO bound tasks).\n",
    "\n",
    "\n",
    "## Background\n",
    "\n",
    "### Horizontal versus vertical scaling\n",
    "\n",
    "Horizontal scaling = **scaling wide** - using many identical or similar workers to solve a problem.\n",
    "\n",
    "Vertical scaling = **scaling tall** - using one large worker to solve a problem.\n",
    "\n",
    "![](../assets/scaling.svg)\n",
    "\n",
    "Similar terminology in business (vertical integration etc).\n",
    "\n",
    "\n",
    "### Fixed versus variable costs\n",
    "\n",
    "Variable costs are a function of scale - fixed costs are constant & independent of scale.\n",
    "\n",
    "There is a trade-off between fixed costs and variable costs.\n",
    "\n",
    "For distributed computation, we balance fixed costs (such time & memory cost to start up processes in `multiprocessing`, time to spin up a Dask cluster on EC2 / ECS) with variable costs (the additional/marginal increase in cost with one additional unit of compute).\n",
    "\n",
    "There can also be additional trade-offs - such as between different fixed costs - for example running a cluster on the cloud:\n",
    "\n",
    "- starting it up each time = high fixed cost of execution time,\n",
    "- running it all the time = high fixed cost CPU time.\n",
    "\n",
    "\n",
    "## Why distribute compute?\n",
    "\n",
    "### To go faster\n",
    "\n",
    "There are diminishing returns on increasing the performance of a single CPU core - there is limited ability to vertically scale on a single CPU core.\n",
    "\n",
    "Distributing work over many CPU cores let's us massively exceed what we can do with a single core.\n",
    "\n",
    "Distributing compute over many CPU cores (parallelism) or across one intelligently (asynchronous) ignores the vertical limit on a single core by going **wide & horizontal with many CPU cores**.  The GPU is an extreme example of this, with thousands of cores per GPU card.\n",
    "\n",
    "Solving two problems will be the  focus of this notebook:\n",
    "\n",
    "1) CPU bound problems,\n",
    "2) IO bound problems.\n",
    "\n",
    "The solutions to these two problems:\n",
    "\n",
    "1. CPU bound = using more hardware/CPU/workers to go faster by running many in parallel,\n",
    "2. IO bound = use the same hardware (single CPU core) to go faster by handing off execution & waiting.\n",
    "\n",
    "\n",
    "### To use more memory \n",
    "\n",
    "Sometimes we want to do calculations on large datasets (larger than memory):\n",
    "\n",
    "1. use many small machines,\n",
    "2. batch data (Dask Dataframe does this) - intelligent use of the same hardware.\n",
    "\n",
    "The third notebook (`3-many-machines.ipynb`) will show how to distribute compute across a Dask cluster on EC2.\n",
    "\n",
    "\n",
    "## Why distribute compute on a single machine?\n",
    "\n",
    "It's easier than many machines- don't need to:\n",
    "\n",
    "- install anything third party,\n",
    "- access/manage remote machines,\n",
    "- sign up for any accounts.\n",
    "\n",
    "Trade-off reducing the fixed overhead costs that come with multiple machines (incl. programmer time) with a limited capacity to scale (one machine)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "devoted-median",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Hardware & Software"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "supreme-marble",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "<center><img src=\"../assets/cores.png\" alt=\"Drawing\" style=\"width: 800px;\"/></center>\n",
    "\n",
    "## CPU cores\n",
    "\n",
    "*Hardware* - also called a processor.  One core can do one thing at a time - execute a single thread.\n",
    "\n",
    "Your machine will have 4-8 (16 if you are lucky).\n",
    "\n",
    "\n",
    "## Threads\n",
    "\n",
    "*Software* - atomic unit of compute in a process.\n",
    "\n",
    "The software representation of a sequence of computation. \n",
    "\n",
    "Memory is shared between threads - making threads the lightest weight, fastest way to speed up compute.\n",
    "\n",
    "\n",
    "## Processes\n",
    "\n",
    "*Software* - a program in execution.\n",
    "\n",
    "Each process has one or more threads - sequential steps of compute that are moved forward by a CPU.\n",
    "\n",
    "Each process has a **dedicated memory space** - making **multiple processes memory intensive** relative to using multiple threads.\n",
    "\n",
    "A process comes with memory overhead - this is traded-off with safety that comes from having separate & independent memory.\n",
    "\n",
    "\n",
    "## Additional detail\n",
    "\n",
    "#### Multi-threading \n",
    "\n",
    "Difference between:\n",
    "\n",
    "- one core taking turns to execute multiple threads in one process,\n",
    "- multiple cores running multiple threads in one process at the same time.\n",
    "\n",
    "Single CPU core multi-threading is an oppourtunity for concurrency.\n",
    "\n",
    "Multiple CPU core multi-threading is an oppourtunity for both concurrency and parallelism.\n",
    "\n",
    "\n",
    "#### Hyperthreading\n",
    "\n",
    "Allows one core to run multiple threads.  One core creates two virtual cores, which can run two threads."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "declared-collaboration",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Concurrency, Parallelism & Asynchrony"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gentle-millennium",
   "metadata": {},
   "source": [
    "## Motivating Examples\n",
    "\n",
    "<center><img src=\"../assets/examples.png\" alt=\"Drawing\" style=\"width: 800px;\"/></center>\n",
    "\n",
    "## Concurrency\n",
    "\n",
    "**Concurrency = handling/managing/doing many things at once**.\n",
    "\n",
    "Opportunities for concurrency in programs are places where the order doesn't matter, such as reading two files from disk - either file can be read first.\n",
    "\n",
    "- tasks can be run in a different order sequentially, in parallel or with overlap.\n",
    "\n",
    "Exploiting concurrency can involve:\n",
    "\n",
    "- using more hardware (ie additional CPU cores),\n",
    "- communicating (ie waiting for an asynchronous callback/future/promise to return).\n",
    "\n",
    "Common examples in computer programs for concurrency:\n",
    "\n",
    "- IO bound problems - reading/writing to disk/network,\n",
    "- CPU bound problems - parallelizable tasks.\n",
    "\n",
    "\n",
    "## Parallelism\n",
    "\n",
    "**Parallelism = doing many things at once** - it is a form of concurrency:\n",
    "\n",
    "- requires many workers (to all work at the same time),\n",
    "- requires independent work - work needs to be split into many tasks that can run at the same time.\n",
    "\n",
    "Opportunities for parallelism in code are in sequential iteration of independent tasks, such as `for` loops or `map`.\n",
    "\n",
    "We can parallelize compute across:\n",
    "\n",
    "- threads (in one CPU core),\n",
    "- CPU cores (in one machine),\n",
    "- multiple machines,\n",
    "- multiple data centres,\n",
    "- multiple regions,\n",
    "- multiple planets.\n",
    "\n",
    "\n",
    "## Asynchrony\n",
    "\n",
    "**Asynchronous programming = handing off the CPU to other tasks while we wait** - it is also a form of concurrency:\n",
    "\n",
    "- ability to wait for outside/external process without blocking the main thread of execution.\n",
    "\n",
    "This gives us a form of parallelism with a single CPU - our main thread can be working on something else while we are waiting for the network or disk.\n",
    "\n",
    "\n",
    "## Examples\n",
    "\n",
    "### You can't grow a tree faster\n",
    "\n",
    "Some jobs cannot be performed concurrently - you just need to wait for the tree to grow.\n",
    "\n",
    "There is no way to split up, separate or independently run any task to speed up how long it takes to grow one tree.\n",
    "\n",
    "<center><img src=\"../assets/tree.jpg\" alt=\"Drawing\" style=\"width: 500px;\"/></center>\n",
    "\n",
    "\n",
    "### You can mow one lawn faster\n",
    "\n",
    "We can split up a lawn into independent sections - introducing additional hardware (mowers) to achieve more by running them in parallel.\n",
    "\n",
    "<center><img src=\"../assets/lawn-full.png\" alt=\"Drawing\" style=\"width: 500px;\"/></center>\n",
    "\n",
    "\n",
    "### You can play many games of chess at once\n",
    "\n",
    "One chess grandmaster can play many games at once:\n",
    "\n",
    "- that game can be suspended so it doesn't block the main thread of execution for the grandmaster, \n",
    "- the grandmaster can later resume the game.\n",
    "\n",
    "A synchronous version would mean the grandmaster would need to sit & wait for the first game - while waiting for the opponent to move.\n",
    "\n",
    "<center><img src=\"../assets/chess.jpg\" alt=\"Drawing\" style=\"width: 500px;\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2505cd6d-b853-4b78-a973-f0fd5bdcd7dc",
   "metadata": {
    "tags": []
   },
   "source": [
    "# CPU bound & IO bound problems"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57220dc6-629b-4e02-ba15-39709f3f7d6d",
   "metadata": {},
   "source": [
    "Computers do three things:\n",
    "\n",
    "1. **compute** - transform data into other data,\n",
    "2. **communicate** - computers can talk to other computers over a network.\n",
    "3. **store** - remember data for access later,\n",
    "\n",
    "This functionality can be mapped to problems or bottlenecks we have when using computers:\n",
    "\n",
    "1. CPU bound problems (compute),\n",
    "2. IO bound problems (communication),\n",
    "3. memory problems (storage).\n",
    "\n",
    "This notebooks focuses on CPU & IO bound problems:\n",
    "\n",
    "1. solve CPU bound problems with `multiprocessing`,\n",
    "2. solve IO bound problems with `asyncio`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "convinced-competition",
   "metadata": {
    "tags": []
   },
   "source": [
    "# `threading`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "forward-jonathan",
   "metadata": {},
   "source": [
    "Threads are the basic unit of computation in a process.\n",
    "\n",
    "Using multiple CPU cores to execute multiple threads gives parallelism across threads.\n",
    "\n",
    "Multi-threading is an efficient way to speed up programs as they all exist in the same process with the same memory space.  This sharing of the same memory space is also multi-threading's weakness - multiple threads accesing the same memory at different times can cause problems like race conditions or deadlocks.\n",
    "\n",
    "These problems are managed by locking access to memory in the correct way - which is hard to program.\n",
    "\n",
    "\n",
    "## Multi-threading in Python\n",
    "\n",
    "**Python is not thread safe** - simultaneous execution of multiple threads in a single process is not safe - using multiple threads to execute one function can lead to different threads mutating the same space in memory.\n",
    "\n",
    "Memory safety in Python is achieved through a Global Interpreter Lock (GIL) - the GIL locks onto a single thread & core.\n",
    "\n",
    "Writing multi-threaded code in Python is possible but hard - see [Raymond Hettinger, Keynote on Concurrency, PyBay 2017](https://www.youtube.com/watch?v=9zinZmE3Ogk).\n",
    "\n",
    "\n",
    "## `threading` in Python - One Thread, No Parallelism\n",
    "\n",
    "What the Python standard library does offer in the `threading` module is the ability to do concurrent computation on a single thread.\n",
    "\n",
    "This makes `threading` suitable only for IO bound tasks - `threading` offers no parallelism across threads.\n",
    "\n",
    "Using threads in Python is challenging - if you have an IO bound task, `asyncio` is a more modern choice - it's mostly programmer preference.\n",
    "\n",
    "\n",
    "## Why not to use `threading`\n",
    "\n",
    "- limited to a single thread of execution at a time (can't do true multi-threading),\n",
    "- `asyncio` offers the same as `threading` - giving `threading` no space in your toolkit.\n",
    "\n",
    "\n",
    "## But you can multi-threading in Python through C/C++\n",
    "\n",
    "In the same way that a tuple isn't really immutable, you can actually safely multi-thread in Python.\n",
    "\n",
    "`numpy` is an example of easy access to the power of fast, multi-threaded computation in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "becoming-leeds",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "marine-boundary",
   "metadata": {
    "tags": []
   },
   "source": [
    "# `multiprocessing`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adult-mapping",
   "metadata": {},
   "source": [
    "`multiprocessing` is a powerful tool for Python programmers - it is a solution to CPU bound problems.\n",
    "\n",
    "\n",
    "## `multiprocessing` is easy to program\n",
    "\n",
    "Of the three Python standard library modules we look at here, `multiprocessing` is the eaisest to implement.  Any `for` or `map` can eaisly be changed from sequential to parallel exection with 2-3 lines of code.\n",
    "\n",
    "\n",
    "## `multiprocessing` has costs\n",
    "\n",
    "Processes do not share memory - they have their own memory space.  This makes them safe but expensive.\n",
    "\n",
    "This cost (increased memory consumption, fixed startup time of n processes) can often be trivial, but is perhaps catastrophic (especially in terms of memory).\n",
    "\n",
    "Another hidden cost with `multiprocessing` is that your subprocesses (created to parallelize compute across) will not print to STDOUT - logging can be more complex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "derived-brass",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers import compute_intensive_task\n",
    "\n",
    "required_words = 8\n",
    "word_length = 1000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unlimited-blair",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit -n 1 -r 1\n",
    "words = []\n",
    "for _ in range(required_words):\n",
    "    words.append(compute_intensive_task(word_length))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "noble-responsibility",
   "metadata": {},
   "source": [
    "First step is to re-write this to use a `map`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "arranged-newark",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit -n 1 -r 1\n",
    "words = list(map(compute_intensive_task, [word_length] * required_words))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "active-microwave",
   "metadata": {},
   "source": [
    "And finally we can convert this to run in parallel with `multiprocessing`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "miniature-above",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit -n 1 -r 1\n",
    "import multiprocessing\n",
    "\n",
    "with multiprocessing.Pool(2) as pool:\n",
    "    words = pool.map(compute_intensive_task, [word_length] * required_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a27948f-0a8e-4873-a6fe-7c76664bdc75",
   "metadata": {
    "tags": []
   },
   "source": [
    "# `asyncio`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unexpected-lecture",
   "metadata": {
    "tags": []
   },
   "source": [
    "`asyncio` was introduced in Python 3.4 - it's a library to write single threaded, concurrent programs using the `async` & `await` syntax/keywords.\n",
    "\n",
    "## `asyncio` is harder to program\n",
    "\n",
    "At the core of using `asyncio` are asynchronous functions that can stop & start - known as co-routines.\n",
    "\n",
    "`asyncio` allow us to switch tasks where we want using `await` (you may also see the older `yield` syntax).\n",
    "\n",
    "Making a Python program asynchronous using `asyncio` requires changing:\n",
    "\n",
    "- how you structure the program (using non-blocking versions of normally blocking network/disk traffic),\n",
    "- how you run in (`asyncio.run` etc).\n",
    "\n",
    "A further challenge using `asyncio` is that Jupyter is already running an `asyncio` event loop - this means we have to run our async examples outside this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e9ed782-96cd-4ea3-aa5a-2421838313fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "asyncio.get_event_loop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b6fe802-9ea0-47ca-90be-35545ab00bde",
   "metadata": {},
   "source": [
    "## `asyncio` is still single threaded\n",
    "\n",
    "One is that it's still single threaded (thanks to the GIL) - so not suitable for parallelizing programs.\n",
    "\n",
    "Another is that using `asyncio` requires using non-blocking versions of things you currently do.\n",
    "\n",
    "This means instead of doing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "express-government",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit -n 1 -r 1\n",
    "\n",
    "import time\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d324ee12-1d84-49cc-bb2d-82e2e95bc8f2",
   "metadata": {},
   "source": [
    "We do something like:\n",
    "\n",
    "```python\n",
    "import asyncio\n",
    "await asyncio.sleep(3)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "institutional-courage",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  need to run in script\n",
    "!python ../src/asyncio_python.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6c3a92b-add1-4603-99ff-6990332734ad",
   "metadata": {},
   "source": [
    "Similar story for any other blocking call we want to unblock:\n",
    "\n",
    "Opening files:\n",
    "\n",
    "`open('filename', 'r')` -> `aiofiles.open('filename', 'r')`,\n",
    "\n",
    "Network requests:\n",
    "\n",
    "`requests.get`\n",
    "\n",
    "versus\n",
    "\n",
    "```\n",
    "async with httpx.AsyncClient() as client:\n",
    "    r = await client.get('https://www.example.com/')\n",
    "```\n",
    "\n",
    "Popular libraries for these calls:\n",
    "- `httpx`, `aiofiles`, `aiohttp`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spatial-adelaide",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spanish-dinner",
   "metadata": {},
   "source": [
    "Now it's your turn ^^\n",
    "\n",
    "Hints:\n",
    "- you can use `$ time python ./your_script.py` to measure execution time (note there are different `time` depending on OS/shell),\n",
    "- answers are in `notebooks/answers.py`.\n",
    "\n",
    "\n",
    "## Exercise\n",
    "\n",
    "Convert the CPU bound code in `./src/cpu_bound.py` to use `multiprocessing`.\n",
    "\n",
    "Hints:\n",
    "\n",
    "- `multiprocessing.Pool().map()`,\n",
    "- `functools.partial` & `pool.starmap` are often useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd4b9549-27f6-4b6c-8621-f319e9efafe3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "41e32386-5a90-44f5-b974-889a67379e47",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "\n",
    "Convert the IO bound code in `./src/io_bound.py` to use `asyncio`.\n",
    "\n",
    "Hints:\n",
    "\n",
    "- write & run the code in a separate Python `.py` script,\n",
    "- you need to make a choice RE how to introduce non-blocking disk/network IO - see `aiofiles`, `aiohttp` or `httpx`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab88e735-0af9-43e1-b7f0-5766a777b675",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "13833151-97d9-42f2-b66b-d058258d0ea4",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "\n",
    "Convert this code to use `multiprocessing` and/or `asyncio` as appropriate.\n",
    "\n",
    "Hints:\n",
    "\n",
    "- where is this a IO bound versus a CPU bound problem?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a7c695a-2d3b-4145-9020-ae01695871ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "\n",
    "Path('./data').mkdir(exist_ok=True)\n",
    "months = [str(month).zfill(2) for month in range(1, 5)]\n",
    "urls = [\n",
    "    f\"http://www.nemweb.com.au/Data_Archive/Wholesale_Electricity/MMSDM/2021/MMSDM_2021_{month}/MMSDM_Historical_Data_SQLLoader/DATA/PUBLIC_DVD_DISPATCH_UNIT_SCADA_2021{month}010000.zip\"\n",
    "    for month in months\n",
    "]\n",
    "\n",
    "def download(url):\n",
    "    print(f\"downloading {url}\")\n",
    "    response = requests.get(url)\n",
    "    assert response.ok\n",
    "    fname = url.split('/')[-1]\n",
    "    Path(f'./data/{fname}').write_bytes(response.content)\n",
    "    \n",
    "    \n",
    "def process(url):\n",
    "    print(f\"processing {url}\")\n",
    "    fname = url.split('/')[-1]\n",
    "    data = pd.read_csv(f'./data/{fname}', skiprows=1)\n",
    "    data = data.groupby('SETTLEMENTDATE').agg('mean', 'std')\n",
    "   \n",
    "\n",
    "def main(urls):\n",
    "    for url in urls:\n",
    "        download(url)\n",
    "        process(url)\n",
    "\n",
    "main(urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c20b87aa-bd94-4716-a416-6a9e1e178f9a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
