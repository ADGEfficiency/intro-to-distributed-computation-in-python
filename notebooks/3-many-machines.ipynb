{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5dbde9b1-4645-460c-a993-fd92e0ea02ef",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Distributed Computation on Many Machines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1e85e96-8634-4e1d-9b0d-6e4ddc4a5b2a",
   "metadata": {},
   "source": [
    "## This notebook will not run in Binder!\n",
    "\n",
    "You can read this notebook on Binder - to run locally it you will need to `$ pip install -r requirements-coiled.txt` (Binder + Dask don't play well).\n",
    "\n",
    "## Outcomes\n",
    "\n",
    "- overview of ecosystem for distributed compute in Python in 2022,\n",
    "- code examples showing how to run Prefect locally, locally async & on a cluster,\n",
    "- demonstration of a AWS/Dask/Coiled/Prefect stack to distribute compute over a cluster on EC2.\n",
    "\n",
    "\n",
    "## Why distribute compute over many machines?\n",
    "\n",
    "There is a limit on the size of a single machine (largest instance on EC2 etc).\n",
    "\n",
    "Many small machines can be larger (& perhaps cheaper) than the largest single machine.\n",
    "\n",
    "Modern distributed compute platforms/environments will be fault tolerant to failures of individual workers - a single EC2 instance won't be."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73efe784-017f-4cd3-9b55-12eac5be8cf6",
   "metadata": {},
   "source": [
    "## Ecosystems\n",
    "\n",
    "Spark:\n",
    "\n",
    "- accessing Scala code with Python bindings,\n",
    "- Databricks is a modern way to run Spark.\n",
    "\n",
    "[Ray](https://docs.ray.io/en/latest/index.html) & [Dask](https://docs.dask.org/en/stable/):\n",
    "\n",
    "- distributed compute frameworks,\n",
    "- Ray is C++ with Python bindings, Dask only Python (?),\n",
    "- DAGs for computation.\n",
    "\n",
    "Tensorflow & PyTorch:\n",
    "\n",
    "- multi-GPU training,\n",
    "- accessing C++ code with Python bindings.\n",
    "\n",
    "Plus more - Celery, lots of AWS Lambda...\n",
    "\n",
    "\n",
    "## Our focus\n",
    "\n",
    "A stack of Dask / Coiled / Prefect / EC2.\n",
    "\n",
    "Requires two accounts - AWS account, Coiled account - Prefect account is optional. \n",
    "\n",
    "\n",
    "## Dask\n",
    "\n",
    "[documentation](https://docs.dask.org/en/stable/)\n",
    "\n",
    "Dask is an execution framework - one scheduler is responsible for executing many workers on many tasks.\n",
    "\n",
    "<center><img src=\"../assets/dask.png\" alt=\"Drawing\" style=\"width: 600px;\"/></center>\n",
    "\n",
    "While Dask is a core part of this stack (it gives us concurrent computation - both parallelism + async), we will not write any low level Dask (or Dask DataFrame) code.\n",
    "\n",
    "\n",
    "## Coiled\n",
    "\n",
    "[documentation](https://docs.coiled.io)\n",
    "\n",
    "<center><img src=\"../assets/coiled-architecture.png\" alt=\"Drawing\" style=\"width: 600px;\"/></center>\n",
    "\n",
    "Manages AWS infrastructure for running Dask clusters on EC2:\n",
    "\n",
    "- turns a `requirements.txt` into a *software environment* - Docker image with `pip install`,\n",
    "\n",
    "\n",
    "## Prefect\n",
    "\n",
    "[documentation Prefect 2.0](https://docs.prefect.io/)\n",
    "\n",
    "Acts as a wrapper around Dask.  Prefect offers more functionality than just Dask execution:\n",
    "\n",
    "- scheduling,\n",
    "- monitoring,\n",
    "- intelligent re-execution of pipelines (aka back-filling).\n",
    "\n",
    "Prefect 2.0 is currently in beta (not yet production ready) - we will be using Prefect 2.0.\n",
    "\n",
    "\n",
    "# Prefect & Dask on a Single Machine\n",
    "\n",
    "Let's start by writing the program from the last exercise of the previous notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6aa8d488-1d22-4ce9-961c-d0c9cfbb3945",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1min 27s ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 1 -r 1\n",
    "!python ../src/naive.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9819d8d-3d0e-45bb-80e2-30a07f26814e",
   "metadata": {},
   "source": [
    "Now try with naive Prefect:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "edec622e-ac4d-43a4-a8bc-7b4e8c666f31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21:31:14.692 | INFO    | prefect.engine - Created flow run 'rough-gorilla' for flow 'main'\n",
      "21:31:14.693 | INFO    | prefect.task_runner.dask - Creating a new Dask cluster with `distributed.deploy.local.LocalCluster`\n",
      "21:31:16.475 | INFO    | prefect.task_runner.dask - The Dask dashboard is available at http://127.0.0.1:8787/status\n",
      "21:31:18.584 | INFO    | Flow run 'rough-gorilla' -  downloading http://www.nemweb.com.au/Data_Archive/Wholesale_Electricity/MMSDM/2021/MMSDM_2021_01/MMSDM_Historical_Data_SQLLoader/DATA/PUBLIC_DVD_DISPATCH_UNIT_SCADA_202101010000.zip\n",
      "21:31:18.934 | INFO    | Flow run 'rough-gorilla' - Created task run 'download-ccd6cdb6-0' for task 'download'\n",
      "21:31:19.355 | INFO    | Flow run 'rough-gorilla' - Submitted task run 'download-ccd6cdb6-0' for execution.\n",
      "21:31:19.356 | INFO    | Flow run 'rough-gorilla' -  processing http://www.nemweb.com.au/Data_Archive/Wholesale_Electricity/MMSDM/2021/MMSDM_2021_01/MMSDM_Historical_Data_SQLLoader/DATA/PUBLIC_DVD_DISPATCH_UNIT_SCADA_202101010000.zip\n",
      "21:31:19.704 | INFO    | Flow run 'rough-gorilla' - Created task run 'process-1cc53e18-0' for task 'process'\n",
      "21:31:19.741 | INFO    | Flow run 'rough-gorilla' - Submitted task run 'process-1cc53e18-0' for execution.\n",
      "21:31:19.742 | INFO    | Flow run 'rough-gorilla' -  downloading http://www.nemweb.com.au/Data_Archive/Wholesale_Electricity/MMSDM/2021/MMSDM_2021_02/MMSDM_Historical_Data_SQLLoader/DATA/PUBLIC_DVD_DISPATCH_UNIT_SCADA_202102010000.zip\n",
      "21:31:20.052 | INFO    | Flow run 'rough-gorilla' - Created task run 'download-ccd6cdb6-1' for task 'download'\n",
      "21:31:20.074 | INFO    | Flow run 'rough-gorilla' - Submitted task run 'download-ccd6cdb6-1' for execution.\n",
      "21:31:20.075 | INFO    | Flow run 'rough-gorilla' -  processing http://www.nemweb.com.au/Data_Archive/Wholesale_Electricity/MMSDM/2021/MMSDM_2021_02/MMSDM_Historical_Data_SQLLoader/DATA/PUBLIC_DVD_DISPATCH_UNIT_SCADA_202102010000.zip\n",
      "21:31:20.418 | INFO    | Flow run 'rough-gorilla' - Created task run 'process-1cc53e18-1' for task 'process'\n",
      "21:31:20.450 | INFO    | Flow run 'rough-gorilla' - Submitted task run 'process-1cc53e18-1' for execution.\n",
      "21:31:20.451 | INFO    | Flow run 'rough-gorilla' -  downloading http://www.nemweb.com.au/Data_Archive/Wholesale_Electricity/MMSDM/2021/MMSDM_2021_03/MMSDM_Historical_Data_SQLLoader/DATA/PUBLIC_DVD_DISPATCH_UNIT_SCADA_202103010000.zip\n",
      "21:31:20.757 | INFO    | Flow run 'rough-gorilla' - Created task run 'download-ccd6cdb6-2' for task 'download'\n",
      "21:31:20.781 | INFO    | Flow run 'rough-gorilla' - Submitted task run 'download-ccd6cdb6-2' for execution.\n",
      "21:31:20.781 | INFO    | Flow run 'rough-gorilla' -  processing http://www.nemweb.com.au/Data_Archive/Wholesale_Electricity/MMSDM/2021/MMSDM_2021_03/MMSDM_Historical_Data_SQLLoader/DATA/PUBLIC_DVD_DISPATCH_UNIT_SCADA_202103010000.zip\n",
      "21:31:21.127 | INFO    | Flow run 'rough-gorilla' - Created task run 'process-1cc53e18-2' for task 'process'\n",
      "21:31:21.149 | INFO    | Flow run 'rough-gorilla' - Submitted task run 'process-1cc53e18-2' for execution.\n",
      "21:31:21.149 | INFO    | Flow run 'rough-gorilla' -  downloading http://www.nemweb.com.au/Data_Archive/Wholesale_Electricity/MMSDM/2021/MMSDM_2021_04/MMSDM_Historical_Data_SQLLoader/DATA/PUBLIC_DVD_DISPATCH_UNIT_SCADA_202104010000.zip\n",
      "21:31:21.489 | INFO    | Flow run 'rough-gorilla' - Created task run 'download-ccd6cdb6-3' for task 'download'\n",
      "21:31:21.506 | INFO    | Flow run 'rough-gorilla' - Submitted task run 'download-ccd6cdb6-3' for execution.\n",
      "21:31:21.507 | INFO    | Flow run 'rough-gorilla' -  processing http://www.nemweb.com.au/Data_Archive/Wholesale_Electricity/MMSDM/2021/MMSDM_2021_04/MMSDM_Historical_Data_SQLLoader/DATA/PUBLIC_DVD_DISPATCH_UNIT_SCADA_202104010000.zip\n",
      "21:31:21.845 | INFO    | Flow run 'rough-gorilla' - Created task run 'process-1cc53e18-3' for task 'process'\n",
      "21:31:21.867 | INFO    | Flow run 'rough-gorilla' - Submitted task run 'process-1cc53e18-3' for execution.\n",
      "21:31:53.172 | INFO    | Flow run 'rough-gorilla' - Finished in state Completed('All states completed.')\n",
      "41.4 s ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 1 -r 1\n",
    "!python ../src/naive_dask_prefect.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29fd3425-7f7a-4e4d-8308-d868990dffcf",
   "metadata": {},
   "source": [
    "Now let's use Prefect with `asyncio`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a524d353-f4fe-4fd7-9b03-f05c3a622302",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21:31:56.419 | INFO    | prefect.engine - Created flow run 'optimal-goose' for flow 'main'\n",
      "21:31:56.420 | INFO    | prefect.task_runner.dask - Creating a new Dask cluster with `distributed.deploy.local.LocalCluster`\n",
      "21:31:58.546 | INFO    | prefect.task_runner.dask - The Dask dashboard is available at http://127.0.0.1:8787/status\n",
      "21:32:00.722 | INFO    | Flow run 'optimal-goose' -  downloading http://www.nemweb.com.au/Data_Archive/Wholesale_Electricity/MMSDM/2021/MMSDM_2021_01/MMSDM_Historical_Data_SQLLoader/DATA/PUBLIC_DVD_DISPATCH_UNIT_SCADA_202101010000.zip\n",
      "21:32:01.030 | INFO    | Flow run 'optimal-goose' - Created task run 'download-ccd6cdb6-0' for task 'download'\n",
      "21:32:01.512 | INFO    | Flow run 'optimal-goose' - Submitted task run 'download-ccd6cdb6-0' for execution.\n",
      "21:32:01.512 | INFO    | Flow run 'optimal-goose' -  processing http://www.nemweb.com.au/Data_Archive/Wholesale_Electricity/MMSDM/2021/MMSDM_2021_01/MMSDM_Historical_Data_SQLLoader/DATA/PUBLIC_DVD_DISPATCH_UNIT_SCADA_202101010000.zip\n",
      "../src/async_prefect.py:38: RuntimeWarning: coroutine 'create_task_run_then_submit' was never awaited\n",
      "  process.submit(url, wait_for=[download_task])\n",
      "21:32:01.513 | INFO    | Flow run 'optimal-goose' -  downloading http://www.nemweb.com.au/Data_Archive/Wholesale_Electricity/MMSDM/2021/MMSDM_2021_02/MMSDM_Historical_Data_SQLLoader/DATA/PUBLIC_DVD_DISPATCH_UNIT_SCADA_202102010000.zip\n",
      "21:32:01.856 | INFO    | Flow run 'optimal-goose' - Created task run 'download-ccd6cdb6-1' for task 'download'\n",
      "21:32:01.885 | INFO    | Flow run 'optimal-goose' - Submitted task run 'download-ccd6cdb6-1' for execution.\n",
      "21:32:01.885 | INFO    | Flow run 'optimal-goose' -  processing http://www.nemweb.com.au/Data_Archive/Wholesale_Electricity/MMSDM/2021/MMSDM_2021_02/MMSDM_Historical_Data_SQLLoader/DATA/PUBLIC_DVD_DISPATCH_UNIT_SCADA_202102010000.zip\n",
      "21:32:01.886 | INFO    | Flow run 'optimal-goose' -  downloading http://www.nemweb.com.au/Data_Archive/Wholesale_Electricity/MMSDM/2021/MMSDM_2021_03/MMSDM_Historical_Data_SQLLoader/DATA/PUBLIC_DVD_DISPATCH_UNIT_SCADA_202103010000.zip\n",
      "21:32:02.429 | INFO    | Flow run 'optimal-goose' - Created task run 'download-ccd6cdb6-2' for task 'download'\n",
      "21:32:02.450 | INFO    | Flow run 'optimal-goose' - Submitted task run 'download-ccd6cdb6-2' for execution.\n",
      "21:32:02.450 | INFO    | Flow run 'optimal-goose' -  processing http://www.nemweb.com.au/Data_Archive/Wholesale_Electricity/MMSDM/2021/MMSDM_2021_03/MMSDM_Historical_Data_SQLLoader/DATA/PUBLIC_DVD_DISPATCH_UNIT_SCADA_202103010000.zip\n",
      "21:32:02.451 | INFO    | Flow run 'optimal-goose' -  downloading http://www.nemweb.com.au/Data_Archive/Wholesale_Electricity/MMSDM/2021/MMSDM_2021_04/MMSDM_Historical_Data_SQLLoader/DATA/PUBLIC_DVD_DISPATCH_UNIT_SCADA_202104010000.zip\n",
      "21:32:02.820 | INFO    | Flow run 'optimal-goose' - Created task run 'download-ccd6cdb6-3' for task 'download'\n",
      "21:32:02.836 | INFO    | Flow run 'optimal-goose' - Submitted task run 'download-ccd6cdb6-3' for execution.\n",
      "21:32:02.836 | INFO    | Flow run 'optimal-goose' -  processing http://www.nemweb.com.au/Data_Archive/Wholesale_Electricity/MMSDM/2021/MMSDM_2021_04/MMSDM_Historical_Data_SQLLoader/DATA/PUBLIC_DVD_DISPATCH_UNIT_SCADA_202104010000.zip\n",
      "21:32:27.777 | INFO    | Flow run 'optimal-goose' - Finished in state Completed('All states completed.')\n",
      "34.5 s ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 1 -r 1\n",
    "!python ../src/async_prefect.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b8a02e-b081-4244-98bf-dcbf8348d09a",
   "metadata": {},
   "source": [
    "# Prefect & Dask Running on a Coiled Cluster (Many Machines)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2edcfbad-b322-4a13-a873-dc699f3ce0ec",
   "metadata": {},
   "source": [
    "<center><img src=\"../assets/many-machine/f2.png\" alt=\"Drawing\" style=\"width: 600px;\"/></center>\n",
    "\n",
    "Requires a few accounts to get setup:\n",
    "\n",
    "- AWS account - cluster will run on EC2,\n",
    "- Coiled account - adds & manages AWS infrastructure needed for a Dask cluster.\n",
    "\n",
    "Stack:\n",
    "\n",
    "- EC2,\n",
    "- Dask,\n",
    "- Prefect,\n",
    "- Coiled.\n",
    "\n",
    "Example of running on a Coiled cluster:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b7f4422-2914-41a3-85c0-233694613d4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing software environment build, returning\n",
      "21:32:38.044 | INFO    | prefect.engine - Created flow run 'complex-urchin' for flow 'main'\n",
      "21:32:38.045 | INFO    | prefect.task_runner.dask - Creating a new Dask cluster with `coiled._beta.cluster.ClusterBeta`\n",
      "21:32:49.927 | INFO    | prefect.task_runner.dask - The Dask dashboard is available at http://54.234.237.186:8787\n",
      "21:32:52.497 | INFO    | Flow run 'complex-urchin' - Created task run 'download-ccd6cdb6-0' for task 'download'\n",
      "21:32:52.824 | INFO    | Flow run 'complex-urchin' - Submitted task run 'download-ccd6cdb6-0' for execution.\n",
      "21:32:53.163 | INFO    | Flow run 'complex-urchin' - Created task run 'process-1cc53e18-0' for task 'process'\n",
      "21:32:53.265 | INFO    | Flow run 'complex-urchin' - Submitted task run 'process-1cc53e18-0' for execution.\n",
      "21:32:53.601 | INFO    | Flow run 'complex-urchin' - Created task run 'download-ccd6cdb6-1' for task 'download'\n",
      "21:32:53.629 | INFO    | Flow run 'complex-urchin' - Submitted task run 'download-ccd6cdb6-1' for execution.\n",
      "21:32:53.946 | INFO    | Flow run 'complex-urchin' - Created task run 'process-1cc53e18-1' for task 'process'\n",
      "21:32:53.977 | INFO    | Flow run 'complex-urchin' - Submitted task run 'process-1cc53e18-1' for execution.\n",
      "21:32:54.323 | INFO    | Flow run 'complex-urchin' - Created task run 'download-ccd6cdb6-2' for task 'download'\n",
      "21:32:54.349 | INFO    | Flow run 'complex-urchin' - Submitted task run 'download-ccd6cdb6-2' for execution.\n",
      "21:32:54.705 | INFO    | Flow run 'complex-urchin' - Created task run 'process-1cc53e18-2' for task 'process'\n",
      "21:32:54.732 | INFO    | Flow run 'complex-urchin' - Submitted task run 'process-1cc53e18-2' for execution.\n",
      "21:32:55.040 | INFO    | Flow run 'complex-urchin' - Created task run 'download-ccd6cdb6-3' for task 'download'\n",
      "21:32:55.071 | INFO    | Flow run 'complex-urchin' - Submitted task run 'download-ccd6cdb6-3' for execution.\n",
      "21:32:55.408 | INFO    | Flow run 'complex-urchin' - Created task run 'process-1cc53e18-3' for task 'process'\n",
      "21:32:55.437 | INFO    | Flow run 'complex-urchin' - Submitted task run 'process-1cc53e18-3' for execution.\n",
      "21:36:54.149 | INFO    | Flow run 'complex-urchin' - Finished in state Completed('All states completed.')\n",
      "4min 26s ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 1 -r 1\n",
    "!python ../src/dask_coiled_prefect.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8f39247-11d2-4404-a309-2e1f22bbd876",
   "metadata": {},
   "source": [
    "# Setting up the AWS/Dask/Coiled/Prefect stack\n",
    "\n",
    "## AWS Setup\n",
    "\n",
    "Pre-requisite is an AWS account.\n",
    "\n",
    "First setup a new IAM user (below I call this user `coiled`) with programmatic access (key + secret key) - remember to download / copy your credentials to CSV!\n",
    "\n",
    "We will use this user to manage & run the Coiled cluster on EC2.\n",
    "\n",
    "Create IAM policies & AWS infrastructure so you can run Dask clusters in your AWS account - see [Coiled AWS setup](https://docs.coiled.io/user_guide/aws-cli.html). \n",
    "\n",
    "[Coiled IAM policies](https://docs.coiled.io/user_guide/aws_reference.html) - one is for setting up the IAM user (don't need if you are using credentials with admin access), the other for spinning up new clusters:\n",
    "\n",
    "- create 2 IAM policies `coiled-setup` & `coiled-ongoing` from JSON,\n",
    "- attach policies to your IAM user.\n",
    "\n",
    "\n",
    "## Coiled account setup\n",
    "\n",
    "[Create a Coiled account](https://cloud.coiled.io/signup) - add your credentials in *Cloud Provider*.\n",
    "\n",
    "Or do the same thing via the shell - [create Coiled API token here](https://cloud.coiled.io/profile).\n",
    "\n",
    "<center><img src=\"../assets/many-machine/f3.png\" alt=\"Drawing\" style=\"width: 600px;\"/></center>\n",
    "\n",
    "```shell\n",
    "$ pip install coiled\n",
    "#  use token here\n",
    "$ coiled login -t $YOURTOKEN\n",
    "$ coiled setup aws\n",
    "```\n",
    "\n",
    "Now you can run the Dask example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f2b1f7-4902-4bd4-9d2f-bd6714dafec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python ../src/dask_coiled.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eefd5264-7368-49a7-ade2-cd3979d7be32",
   "metadata": {},
   "source": [
    "## Optional - Adding Prefect Cloud\n",
    "\n",
    "Requires a Prefect Cloud account.\n",
    "\n",
    "<center><img src=\"../assets/many-machine/f4.png\" alt=\"Drawing\" style=\"width: 600px;\"/></center>\n",
    "\n",
    "\n",
    "```shell\n",
    "$ prefect cloud workspace set --workspace \"adamgreenadgefficiencycom/kiwipycon-tutorial\"\n",
    "$ prefect cloud login -k $YOUR_PREFECT_API_KEY\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
